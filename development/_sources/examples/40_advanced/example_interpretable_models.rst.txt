
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/40_advanced/example_interpretable_models.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_40_advanced_example_interpretable_models.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_40_advanced_example_interpretable_models.py:


====================
Interpretable models
====================

The following example shows how to inspect the models which *auto-sklearn*
optimizes over and how to restrict them to an interpretable subset.

.. GENERATED FROM PYTHON SOURCE LINES 10-16

.. code-block:: default

    from pprint import pprint

    import autosklearn.classification
    import sklearn.datasets
    import sklearn.metrics








.. GENERATED FROM PYTHON SOURCE LINES 17-23

Show available classification models
====================================

We will first list all classifiers Auto-sklearn chooses from. A similar
call is available for preprocessors (see below) and regression (not shown)
as well.

.. GENERATED FROM PYTHON SOURCE LINES 23-28

.. code-block:: default

    from autosklearn.pipeline.components.classification import ClassifierChoice

    for name in ClassifierChoice.get_components():
        print(name)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    adaboost
    bernoulli_nb
    decision_tree
    extra_trees
    gaussian_nb
    gradient_boosting
    k_nearest_neighbors
    lda
    liblinear_svc
    libsvm_svc
    mlp
    multinomial_nb
    passive_aggressive
    qda
    random_forest
    sgd




.. GENERATED FROM PYTHON SOURCE LINES 29-31

Show available preprocessors
============================

.. GENERATED FROM PYTHON SOURCE LINES 31-39

.. code-block:: default


    from autosklearn.pipeline.components.feature_preprocessing import (
        FeaturePreprocessorChoice,
    )

    for name in FeaturePreprocessorChoice.get_components():
        print(name)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    densifier
    extra_trees_preproc_for_classification
    extra_trees_preproc_for_regression
    fast_ica
    feature_agglomeration
    kernel_pca
    kitchen_sinks
    liblinear_svc_preprocessor
    no_preprocessing
    nystroem_sampler
    pca
    polynomial
    random_trees_embedding
    select_percentile_classification
    select_percentile_regression
    select_rates_classification
    select_rates_regression
    truncatedSVD




.. GENERATED FROM PYTHON SOURCE LINES 40-42

Data Loading
============

.. GENERATED FROM PYTHON SOURCE LINES 42-48

.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(
        X, y, random_state=1
    )








.. GENERATED FROM PYTHON SOURCE LINES 49-57

Build and fit a classifier
==========================

We will now only use a subset of the given classifiers and preprocessors.
Furthermore, we will restrict the ensemble size to ``1`` to only use the
single best model in the end. However, we would like to note that the
choice of which models is deemed interpretable is very much up to the user
and can change from use case to use case.

.. GENERATED FROM PYTHON SOURCE LINES 57-74

.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder="/tmp/autosklearn_interpretable_models_example_tmp",
        include={
            "classifier": ["decision_tree", "lda", "sgd"],
            "feature_preprocessor": [
                "no_preprocessing",
                "polynomial",
                "select_percentile_classification",
            ],
        },
        ensemble_size=1,
    )
    automl.fit(X_train, y_train, dataset_name="breast_cancer")





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/runner/work/auto-sklearn/auto-sklearn/autosklearn/metalearning/metalearning/meta_base.py:76: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
      self.metafeatures = self.metafeatures.append(metafeatures)
    /home/runner/work/auto-sklearn/auto-sklearn/autosklearn/metalearning/metalearning/meta_base.py:80: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
      self.algorithm_runs[metric].append(runs)

    AutoSklearnClassifier(ensemble_size=1,
                          include={'classifier': ['decision_tree', 'lda', 'sgd'],
                                   'feature_preprocessor': ['no_preprocessing',
                                                            'polynomial',
                                                            'select_percentile_classification']},
                          per_run_time_limit=30, time_left_for_this_task=120,
                          tmp_folder='/tmp/autosklearn_interpretable_models_example_tmp')



.. GENERATED FROM PYTHON SOURCE LINES 75-77

Print the final ensemble constructed by auto-sklearn
====================================================

.. GENERATED FROM PYTHON SOURCE LINES 77-80

.. code-block:: default


    pprint(automl.show_models(), indent=4)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    {   33: {   'balancing': Balancing(random_state=1),
                'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7f099c557a60>,
                'cost': 0.007092198581560294,
                'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7f09a10a6cd0>,
                'ensemble_weight': 1.0,
                'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7f099c557f10>,
                'model_id': 33,
                'rank': 1,
                'sklearn_classifier': SGDClassifier(alpha=0.0015964489518614283, eta0=0.025525677555219152,
                  learning_rate='invscaling', loss='log', max_iter=1024,
                  penalty='l1', random_state=1, tol=1.8911616385527802e-05,
                  warm_start=True)}}




.. GENERATED FROM PYTHON SOURCE LINES 81-83

Get the Score of the final ensemble
===================================

.. GENERATED FROM PYTHON SOURCE LINES 83-86

.. code-block:: default


    predictions = automl.predict(X_test)
    print("Accuracy score:", sklearn.metrics.accuracy_score(y_test, predictions))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Accuracy score: 0.958041958041958





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 1 minutes  58.473 seconds)


.. _sphx_glr_download_examples_40_advanced_example_interpretable_models.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/auto-sklearn/master?urlpath=lab/tree/notebooks/examples/40_advanced/example_interpretable_models.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_interpretable_models.py <example_interpretable_models.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_interpretable_models.ipynb <example_interpretable_models.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
